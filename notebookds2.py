# -*- coding: utf-8 -*-
"""notebookDS2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bevok_gbRt_hdJ0JxqeZnAOS1Iux-le2

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Rozaq Leksono
- Email: rozaql47@gmail.com
- Id Dicoding:

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import confusion_matrix
import joblib

"""### Menyiapkan data yang akan diguankan"""

# Read data
df = pd.read_csv('/content/data.csv',delimiter=';')

# Menampilkan lima data teratas
df.head()

"""## Data Understanding"""

df.info()

"""Output code di atas memberikan informasi:

- Terdapat 4424 baris

- Terdapat 37 kolom

- Terdapat kolom kategorikal dan numerik

### Cek missing value
"""

print(df.isnull().values.any())
print(df.isna().sum())

"""Output code di atas memberikan informasi :

- Tidak terdapat missing value pada data

### Cek duplikat
"""

print(df.duplicated().sum())

"""Output code di atas memberikan informasi :

- Tidak terdapat duplikat pada data
"""

df.describe()

# Identifikasi kolom numerical
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

plt.figure(figsize=(15, 20))
for i, col in enumerate(numerical_columns, 1):
    plt.subplot(len(numerical_columns) // 3 + 1, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

"""Output code di atas memberikan informasi :

- Tidak terdapat data yang aneh dikarenakan sebagian besar data dalam bentuk numerik, meskipun biasanya kolom tersebut ber bentuk kategorikal
"""

categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    plt.figure(figsize=(10, 6))
    sns.countplot(x=col, data=df)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.show()

"""Output code di atas memberikan informasi :


- Terdapat tiga kategori pada kolom status yaitu dropout, graduate, dan enrolled.

- Kategori graduate memiliki jumlah paling tinggi.
- Kategori enrolled memiliki jumlah paling rendah.
"""

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=False)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Plot matriks korelasi
plt.figure(figsize=(40, 30))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of All Variables (Including Encoded Categorical Features)')
plt.show()

"""Output code di atas memberikan informasi :

- kolom dengan korelasi positif lebih sedikit dibanding kolom dengan korelasi negatif
"""

# Mengubah kolom target 'Status' menjadi numerik
status_mapping = {'Dropout': 0,'Enrolled':1,'Graduate': 2}
df_mapping = df.copy()
df_mapping['Status'] = df['Status'].replace(status_mapping)

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal (kecuali kolom target 'Status')
df_encoded = pd.get_dummies(df_mapping, columns=[col for col in categorical_columns if col != 'Status'], drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Ambil korelasi dengan kolom 'Status'
status_correlation = correlation_matrix["Status"].sort_values(ascending=False)

factors = status_correlation
factors = factors.drop('Status')

# Plot the top 10 correlations
plt.figure(figsize=(10, 8))
sns.barplot(x=factors.values[:10], y=factors.index[:10], dodge=False, palette="coolwarm")
plt.title("korelasi tertinggi dengan status")
plt.xlabel("Correlation with Status")
plt.show()

"""## Data Preparation / Preprocessing

Salin dataset
"""

# Melakukan duplikasi dataset
df_cleaned = df.copy()

"""drop kolom yang tidak dibutuhkan"""

df_cleaned.drop(columns=['Marital_status',
                          'Age_at_enrollment',
                          'Application_mode',
                          'Application_order',
                          'Course',
                          'Previous_qualification',
                          'Nacionality',
                          'Mothers_qualification',
                          'Fathers_qualification',
                          'Mothers_occupation',
                          'Fathers_occupation',
                          'Educational_special_needs',
                          'International',
                          'Curricular_units_1st_sem_evaluations',
                          'Curricular_units_1st_sem_without_evaluations',
                          'Curricular_units_2nd_sem_evaluations',
                          'Curricular_units_2nd_sem_without_evaluations',
                          'Unemployment_rate',
                          'Inflation_rate',
                         'GDP'], axis=1, inplace=True)

df_cleaned.info()

df_cleaned['Gender'] = df['Gender'].astype(str).replace({'0': 'Male', '1': 'Female'})
df_cleaned['Displaced'] = df['Displaced'].astype(str).replace({'0': 'No', '1': 'Yes'})
df_cleaned['Debtor'] = df['Debtor'].astype(str).replace({'0': 'No', '1': 'Yes'})
df_cleaned['Scholarship_holder'] = df['Scholarship_holder'].astype(str).replace({'0': 'No', '1': 'Yes'})
df_cleaned['Tuition_fees_up_to_date'] = df['Tuition_fees_up_to_date'].astype(str).replace({'0': 'No', '1': 'Yes'})
df_cleaned['Daytime_evening_attendance'] = df['Daytime_evening_attendance'].astype(str).replace({'0': 'Evening', '1': 'Daytime'})
df_cleaned['Status'] = df['Status'].astype(str).replace({'0': 'Dropout', '1': 'Graduate'})

"""save dataset untuk dashboard"""

df_cleaned.to_csv('df_clean.csv', index=False)

"""- standarisasi fitur numerik

- one hot encoding untuk fitur kategorikal.
"""

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Standardisasi fitur numerik
scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

# One-hot encoding untuk fitur kategorikal
df = pd.get_dummies(df, columns=categorical_columns, drop_first=False)

#Mengubah nilai True dan False menjadi 1 dan 0
df = df.astype(int)

"""- Memisahkan kolom fitur dan kolom target(memilih 10 kolom dengan korelasi tertinggi)

- Membagi menjadi data train dan test dengan rasio 8:2.

"""

# Memisahkan fitur (X) dan target (y)
X = df.drop(['Status_Dropout','Status_Enrolled','Status_Graduate'], axis=1)
X = X[['Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Tuition_fees_up_to_date_Yes', 'Scholarship_holder_Yes', 'Curricular_units_2nd_sem_enrolled', 'Curricular_units_1st_sem_enrolled', 'Admission_grade', 'Displaced_Yes']]
y = df[['Status_Dropout','Status_Enrolled','Status_Graduate']]

# Membagi data menjadi training dan testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modeling

Melakukan modeling dengan random forest
"""

# Initialize the Random Forest classifier
rdf_model = RandomForestClassifier()

# Define the grid of hyperparameters
param_grid1 = {
    'n_estimators': [100, 200, 300, 400],
    'max_depth': [3, 5, 7, 9],
    'criterion': ['gini', 'entropy']
}

# Initialize GridSearchCV
gs = GridSearchCV(
    estimator=rdf_model,
    param_grid=param_grid1,
    cv=5,
    n_jobs=-1,
    scoring='accuracy'
)

# Train the classifier using GridSearchCV
clf_rf_grid = gs.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf_rf_grid.predict(X_test)

# Print the best parameters found by GridSearchCV
print("Best parameters:", clf_rf_grid.best_params_)

# Calculate and print the test accuracy
test_accuracy = accuracy_score(y_test, y_pred)
print("The test accuracy score of Random Forest Classifier is", test_accuracy)

"""## Evaluation"""

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Classification Report:\n", report)

"""save model"""

# Simpan scaler
joblib.dump(scaler, 'scaler.pkl')

joblib.dump(clf_rf_grid, 'Model.joblib')

!pip freeze > requirements.txt